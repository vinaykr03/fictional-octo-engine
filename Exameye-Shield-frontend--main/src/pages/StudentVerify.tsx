import { useState, useEffect, useRef } from "react";
import { useNavigate } from "react-router-dom";
import { Shield, Camera, Mic, User, ArrowRight } from "lucide-react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Progress } from "@/components/ui/progress";
import { toast } from "sonner";

const MICROPHONE_THRESHOLD = 10; // percentage (approx)

const StudentVerify = () => {
  const navigate = useNavigate();
  const [studentData, setStudentData] = useState<any>(null);
  const [checks, setChecks] = useState({
    camera: { status: 'waiting', message: 'Waiting...' },
    sound: { status: 'waiting', message: 'Waiting...' },
    face: { status: 'waiting', message: 'Waiting...' },
  });
  const [verificationStarted, setVerificationStarted] = useState(false);
  const [progress, setProgress] = useState(0);
  const [soundDetected, setSoundDetected] = useState(false);

  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);

  useEffect(() => {
    const data = sessionStorage.getItem('studentData');
    if (!data) {
      toast.error("Please register first");
      navigate('/register');
      return;
    }
    setStudentData(JSON.parse(data));

    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, [navigate]);

  const startVerification = async () => {
    setVerificationStarted(true);
    setProgress(0);

    // Step 1: Camera Access
    setChecks(prev => ({ ...prev, camera: { status: 'checking', message: 'Requesting access...' } }));
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { width: 640, height: 480 }, 
        audio: true 
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
      }

      streamRef.current = stream;
      setChecks(prev => ({ ...prev, camera: { status: 'success', message: 'Camera connected' } }));
      setProgress(20);

      // Sound detection - Simple check if sound is coming or not
      setChecks(prev => ({ ...prev, sound: { status: 'checking', message: 'Checking for sound...' } }));
      
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      let soundDetected = false;
      let checkCount = 0;
      const maxChecks = 40; // 4 seconds
      
      // Check for sound input
      await new Promise((resolve) => {
        const checkSound = () => {
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
          
          console.log(`ðŸ”Š Sound check: audio level = ${average.toFixed(1)}`);
          
          if (average >= MICROPHONE_THRESHOLD) {
            soundDetected = true;
            console.log(`âœ… Sound detected!`);
            resolve(null);
          } else {
            checkCount++;
            if (checkCount >= maxChecks) {
              console.log(`âŒ No sound detected after 4 seconds`);
              resolve(null);
            } else {
              setTimeout(checkSound, 100);
            }
          }
        };
        checkSound();
      });
      
      audioContext.close();
      
      // Update UI based on result
      if (soundDetected) {
        setChecks(prev => ({ ...prev, sound: { status: 'success', message: 'Sound detected' } }));
        setSoundDetected(true);
      } else {
        setChecks(prev => ({ ...prev, sound: { status: 'error', message: 'No sound detected' } }));
        setSoundDetected(false);
      }
      
      setProgress(40);

      // Step 2: Wait for camera to be ready
      await new Promise(resolve => setTimeout(resolve, 1000));

      // Step 3: Face Detection Check - Use proctoring backend service
      setChecks(prev => ({ ...prev, face: { status: 'checking', message: 'Verifying face position...' } }));
      
      if (videoRef.current) {
        try {
          // Use window.location.origin to ensure we use the same domain
          const PROCTORING_API_URL = import.meta.env.VITE_PROCTORING_API_URL || window.location.origin;
          console.log('Starting proctoring service verification...');
          console.log('Proctoring API URL:', PROCTORING_API_URL);
          
          // Capture frame from video
          const canvas = document.createElement('canvas');
          canvas.width = videoRef.current.videoWidth;
          canvas.height = videoRef.current.videoHeight;
          const ctx = canvas.getContext('2d');
          if (!ctx) throw new Error('Failed to get canvas context');
          
          ctx.drawImage(videoRef.current, 0, 0);
          const frameBase64 = canvas.toDataURL('image/jpeg');
          
          // Call proctoring service environment check
          console.log('Calling environment check at:', `${PROCTORING_API_URL}/api/environment-check`);
          const envResponse = await fetch(`${PROCTORING_API_URL}/api/environment-check`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ frame_base64: frameBase64 })
          });
          
          console.log('Environment check response status:', envResponse.status);
          
          if (!envResponse.ok) {
            const errorText = await envResponse.text();
            console.error('Environment check failed:', errorText);
            throw new Error(`Environment check failed: ${envResponse.status} ${errorText}`);
          }
          
          const envResult = await envResponse.json();
          console.log('Environment check result:', envResult);

          // Update face detection check - Show actual result
          setChecks(prev => ({ 
            ...prev, 
            face: { 
              status: envResult.face_detected ? (envResult.face_centered ? 'success' : 'warning') : 'error',
              message: envResult.face_detected 
                ? (envResult.face_centered ? 'Face verified and centered' : 'Please center your face in the camera')
                : 'No face detected - Please position yourself in front of camera'
            } 
          }));
          setProgress(70);

          // Calibration: Get head pose for future reference
          if (envResult.face_detected) {
            const calibrationResponse = await fetch(`${PROCTORING_API_URL}/api/calibrate`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ frame_base64: frameBase64 })
            });
            
            if (calibrationResponse.ok) {
              const calibration = await calibrationResponse.json();
              if (calibration.success) {
                console.log('Calibration successful:', calibration);
                sessionStorage.setItem('calibration', JSON.stringify({
                  pitch: calibration.pitch,
                  yaw: calibration.yaw
                }));
                toast.success('Proctoring system ready!');
              }
            }
          }
          
          setProgress(85);
          console.log('Proctoring service connected successfully');
          
          // STRICT VALIDATION - All checks must pass
          
          // Check 1: Sound MUST be detected
          if (!soundDetected) {
            toast.error("No sound detected! Please make some noise or speak to test sound detection, then try verification again.", {
              duration: 6000
            });
            setVerificationStarted(false);
            return; // Block exam start
          }
          
          // Check 2: Face MUST be detected to proceed
          if (!envResult.face_detected) {
            toast.error("Face not detected! Please position yourself in front of the camera and try again.");
            setVerificationStarted(false);
            return; // Block exam start
          }
          
        } catch (error) {
          console.error('Verification error:', error);
          console.error('Error details:', error instanceof Error ? error.message : String(error));
          toast.error("Connection to proctoring service failed. Please try again.");
          
          // Show actual error - don't allow proceeding with bad setup
          setChecks(prev => ({ 
            ...prev, 
            face: { status: 'error', message: 'Unable to verify - Service unavailable' }
          }));
          
          setProgress(60);
          setVerificationStarted(false);
          return; // Don't proceed to exam
        }
      }

      await new Promise(resolve => setTimeout(resolve, 500));
      setProgress(100);

      toast.success("Verification complete! Proceeding to compatibility checks...");
      
      setTimeout(() => {
        navigate('/compatibility');
      }, 1500);

    } catch (error: any) {
      console.error('Verification error:', error);
      if (error.name === 'NotAllowedError') {
        setChecks(prev => ({ ...prev, camera: { status: 'error', message: 'Access denied' } }));
        toast.error("Please allow camera access");
      } else {
        toast.error("Verification failed: " + error.message);
      }
    }
  };

  const getStatusIcon = (status: string, Icon: any) => {
    const baseClass = "w-5 h-5";
    if (status === 'success') return <Icon className={`${baseClass} text-primary`} />;
    if (status === 'error') return <Icon className={`${baseClass} text-destructive`} />;
    if (status === 'checking') return <Icon className={`${baseClass} text-primary animate-pulse`} />;
    return <Icon className={`${baseClass} text-muted-foreground`} />;
  };

  if (!studentData) return null;

  return (
    <div className="min-h-screen bg-background p-4">
      <div className="container mx-auto max-w-6xl py-8">
        <div className="grid md:grid-cols-2 gap-6">
          {/* Camera Preview */}
          <Card>
            <CardContent className="p-6">
              <h2 className="text-xl font-bold mb-4">Camera Preview</h2>
              <div className="aspect-video bg-muted rounded-lg overflow-hidden flex items-center justify-center">
                {verificationStarted ? (
                  <video 
                    ref={videoRef} 
                    autoPlay 
                    muted 
                    className="w-full h-full object-cover"
                  />
                ) : (
                  <Camera className="w-16 h-16 text-muted-foreground" />
                )}
              </div>
            </CardContent>
          </Card>

          {/* Verification Progress */}
          <Card>
            <CardContent className="p-6">
              <h2 className="text-xl font-bold mb-4">Verification Progress</h2>
              
              <Progress value={progress} className="mb-6 h-3" />

              <div className="space-y-4 mb-6">
                <div className="flex items-center gap-3">
                  {getStatusIcon(checks.camera.status, Camera)}
                  <div className="flex-1">
                    <p className="font-semibold">Camera Access</p>
                    <p className="text-sm text-muted-foreground">{checks.camera.message}</p>
                  </div>
                </div>

                <div className="flex items-center gap-3">
                  {getStatusIcon(checks.sound.status, Mic)}
                  <div className="flex-1">
                    <p className="font-semibold">Sound Detection</p>
                    <p className="text-sm text-muted-foreground">{checks.sound.message}</p>
                  </div>
                </div>

                <div className="flex items-center gap-3">
                  {getStatusIcon(checks.face.status, User)}
                  <div className="flex-1">
                    <p className="font-semibold">Face Detection</p>
                    <p className="text-sm text-muted-foreground">{checks.face.message}</p>
                  </div>
                </div>
              </div>

              {!verificationStarted && (
                <Button 
                  onClick={startVerification} 
                  className="w-full"
                  size="lg"
                >
                  Start Verification
                  <ArrowRight className="w-4 h-4 ml-2" />
                </Button>
              )}
            </CardContent>
          </Card>
        </div>

        {/* Before you start */}
        <Card className="mt-6">
          <CardContent className="p-6">
            <h3 className="font-bold mb-4">Before you start:</h3>
            <ul className="space-y-2">
              <li className="flex items-center gap-2 text-sm">
                <span className="w-1.5 h-1.5 rounded-full bg-primary"></span>
                Position yourself at the center of the camera
              </li>
              <li className="flex items-center gap-2 text-sm">
                <span className="w-1.5 h-1.5 rounded-full bg-primary"></span>
                No other person should be visible
              </li>
              <li className="flex items-center gap-2 text-sm">
                <span className="w-1.5 h-1.5 rounded-full bg-primary"></span>
                Make some sound to verify audio detection
              </li>
            </ul>
          </CardContent>
        </Card>
      </div>
    </div>
  );
};

export default StudentVerify;
